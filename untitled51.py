# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16McrUNzbzd35lDg-SEQ-x5HzrV_yNGrT
"""

!pip install transformers datasets torch # transformers, datasets ve torch adlı üç Python kütüphanesini sisteme kurar.

pip install optuna #Optuna kütüphanesini sisteme yukler

# Gerekli kütüphanelerin yüklenmesi
import pandas as pd
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from sklearn.metrics import classification_report
import optuna
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords') #islevsiz kelimeleri indiriyoruz

# Türkçe stop-word seti
stop_words = set(stopwords.words('turkish'))

from google.colab import files #csv dosyası yukleme alani

uploaded = files.upload()

import chardet

with open('magaza_yorumlari.csv', 'rb') as rawdata:
    result = chardet.detect(rawdata.read(100))

print(result['encoding'])  # Tespit edilen kodlamayı yazdırır

df = pd.read_csv('magaza_yorumlari.csv', encoding=result['encoding'])  # Tespit edilen kodlamayı kullanır

print(df.head())#ilk bes kayit

print("Satır ve sütun sayısı:", df.shape)#veriseti boyutu

print(df.dtypes)#veri seti tipleri

print(df.info())#veri seti bilgisi

print(df.isnull().sum()) #veri setindeki bos degerlerin sayısı

print(df.describe()) #veri setinin istatiksel sonucları

print(df.columns) #veri setinin sutun bilgisi

print(df.tail(10)) #veri setinin sondan 10 satırının bilgisi

#Görüş ve Durum sütunlarındaki tüm farklı değerleri (tekrar etmeden) yazdırıyoruz
print(df['Görüş'].unique())
print(df['Durum'].unique())

# Veri temizleme
df['Görüş'] = df['Görüş'].astype(str)
df['Yorum'] = df['Görüş'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))

# Sınıfları numerik değerlere dönüştürme
df['Durum'] = df['Durum'].map({'Olumlu': 1, 'Olumsuz': 0})  # Etiketleri numerik değerlere çevir

# Veri Hugging Face Dataset formatına dönüştürülüyor
from datasets import Dataset
dataset = Dataset.from_pandas(df.rename(columns={'Yorum': 'text', 'Durum': 'labels'}))

# Model ve tokenizer yükleme
model_name = "dbmdz/bert-base-turkish-cased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # İki sınıf için num_labels=2

# Veri tokenizasyonu
def preprocess_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(preprocess_function, batched=True)

# Veriyi eğitim ve test setlerine ayırma
train_test_split = tokenized_datasets.train_test_split(test_size=0.2)
train_dataset = train_test_split["train"]
test_dataset = train_test_split["test"]

# Objective fonksiyonu tanımlanıyor
def objective(trial):
    # Hiperparametreler
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)  # Logaritmik dağılım
    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 5)

    # Eğitim parametrelerini ayarlıyoruz
    training_args = TrainingArguments(
        output_dir="./results",
        eval_strategy="epoch",  # 'evaluation_strategy' yerine 'eval_strategy' kullanıyoruz
        learning_rate=learning_rate,
        per_device_train_batch_size=16,
        per_device_eval_batch_size=16,
        num_train_epochs=num_train_epochs,
        weight_decay=0.01,
        save_strategy="epoch",
        load_best_model_at_end=True,
        logging_dir='./logs',
        logging_steps=10,
        report_to="none",  # wandb'yi devre dışı bırakmak için

    )

    # Trainer nesnesi oluşturuluyor
    trainer = Trainer(
        model=model,  # model burada önceden tanımlanmalı
        args=training_args,
        train_dataset=train_dataset,  # train_dataset burada tanımlanmalı
        eval_dataset=test_dataset,  # test_dataset burada tanımlanmalı
    )

    # Modeli eğitme ve değerlendirme
    trainer.train()
    eval_results = trainer.evaluate()

    # Değerlendirme doğruluğunu geri döndürüyoruz
    return eval_results["eval_loss"]

import optuna

# Optuna çalıştırılıyor
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=1)  # Daha fazla deneme için n_trials değerini artırabiliriz

# En iyi parametreler
best_params = study.best_params
print("En İyi Parametreler:", best_params)

import os

# W&B'yi devre dışı bırakmak için yoksa hata veriyodu
os.environ["WANDB_DISABLED"] = "true"
# En iyi parametrelerle model eğitimi
training_args = TrainingArguments(
    output_dir="./final_model",
    eval_strategy="epoch",
    learning_rate=best_params['learning_rate'],
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=best_params['num_train_epochs'],
    weight_decay=0.01,
    save_strategy="epoch",
    load_best_model_at_end=True,
    logging_dir='./final_logs',
    logging_steps=10,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

trainer.train()

# Model değerlendirme
predictions = trainer.predict(test_dataset)
pred_labels = np.argmax(predictions.predictions, axis=1)
true_labels = test_dataset["labels"]

print(classification_report(true_labels, pred_labels))

# Model ve tokenizer kaydetme
model.save_pretrained("./saved_model")
tokenizer.save_pretrained("./saved_model")

print(eval_results.keys()) #dogruluk oranı grafigi cizdrmek icin anahtari bulmamiz gerek

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import numpy as np


import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import numpy as np

# Doğruluk oranını çizen bir grafik
accuracy = eval_results.get("accuracy", None)  # Doğruluk metriği varsa al
if accuracy is not None:
    print(f"Doğruluk: {accuracy}")
else:
    print("Doğruluk metriği bulunamadı.")
    accuracy = 0  # Doğruluk metriği bulunmazsa varsayılan bir değer atanabilir.

# Epoch bilgisi
epochs = list(range(1, best_params['num_train_epochs'] + 1))

plt.figure(figsize=(8, 6))
plt.plot(epochs, [accuracy] * len(epochs), marker='o', label="Doğruluk")
plt.xlabel("Epoch")
plt.ylabel("Doğruluk")
plt.title("Model Doğruluk Grafiği")
plt.legend()
plt.grid()
plt.show()

# Sınıflandırma raporu için bir bar grafiği
report = classification_report(true_labels, pred_labels, output_dict=True)
print("Classification Report Keys:", report.keys())  # Anahtarları kontrol et

# Raporun anahtarlarına göre kategorileri ayarlayın
categories = list(report.keys())[:-3]  # Son üç anahtar genel metriklere ait

precision = []
recall = []

# Rapor kategorilerini kontrol et ve değerleri ekle
for cat in categories:
    if cat in report:
        precision.append(report[cat].get('precision', 0))  # Precision değeri varsa al
        recall.append(report[cat].get('recall', 0))       # Recall değeri varsa al
    else:
        print(f"{cat} kategorisi raporda bulunamadı.")

x = np.arange(len(categories))

plt.figure(figsize=(10, 6))
plt.bar(x - 0.2, precision, 0.4, label="Precision")
plt.bar(x + 0.2, recall, 0.4, label="Recall")
plt.xticks(x, categories, rotation=45)  # Kategori isimlerini döndür
plt.ylabel("Skor")
plt.title("Sınıflandırma Raporu")
plt.legend()
plt.tight_layout()
plt.show()

import torch
import numpy as np

# Cihazı belirleyin (GPU varsa GPU, yoksa CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Modeli cihaza taşıyoruz
model = model.to(device)

# Kullanıcıdan veri girişi alalım
user_input = input("Yorumunuzu girin: ")

# Yorum verisini tokenize etme
inputs = tokenizer(user_input, padding="max_length", truncation=True, return_tensors="pt", max_length=512)

# Token'ları cihaza taşıyoruz
inputs = {key: value.to(device) for key, value in inputs.items()}

# Modeli kullanarak tahmin yapalım
with torch.no_grad():
    model.eval()  # Modeli değerlendirme moduna alıyoruz
    outputs = model(**inputs)
    logits = outputs.logits
    prediction = np.argmax(logits.cpu().numpy(), axis=1)  # Tahminin indeksini alıyoruz

# Tek tahmin sonucunu kullanıyoruz (ilk öğe)
if prediction[0] == 1:
    print("Bu yorum olumlu.")
else:
    print("Bu yorum olumsuz.")